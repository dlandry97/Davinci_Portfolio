---
title: BBall Bot
layout: post
post-image: "/Davinci_Portfolio/assets/BBall/BBallBot.gif"
description: This robot is designed to shoot basketballs as part of a senior design competition at Purdue University.
tags:
- Robotics
- Engineering
- Basketball
- Design
- Purdue
---

This design competition scored the ability for a robot to shoot baskets from a variety of points on the court, free throws, and autonomous aiming. The constraints of this project were that the robot must have some anatomical relation to human linkages, meaning that there could not be any joints that move outside of a human range of motion, such as 360 degree joint rotation or flywheels.

<!-- ![freethrow](/Davinci_portfolio/assets/BBall/Freethrow.gif) -->


**Design**<br>
To mimic the anatomical form of a human arm, we designed our robot to have a hand, wrist, and forearm. The forearm is actuated by a pneumatic piston. The wrist angle was designed to be adjustable but does not actuate during the throw. 

![robotCad](/Davinci_Portfolio/assets/BBall/bballbotCAD.png)

The hand gripper was designed to release the ball at an exact point of the throw. The gripper was designed to use a bicycle break cable system to release the ball when actuated. The cable system actuated the gripper using the tension force between a different portion of the arm. The system could be mounted in different locations allowing the point of release to be adjustable.

![gripperCad](/Davinci_Portfolio/assets/BBall/gripperCad.png)


**Build**<br>
Starting with a barstool as a base, we make the main piston actuated arm out of 80/20 components. We made the remaining portion of the arm out of lightweight carbon fiber to reduce the weight and inertial load. The gripper, originally designed with 80/20 components, was redesigned with 3d printed components and carbon fiber tubes to reduce inertial load as well.

![gripper](/Davinci_Portfolio/assets/BBall/Gripper.jpg)

The actuation of the pneumatic piston was powerful and heavy enough to require over 100kg of added weight to the base of the robot. Without the weight, the robot would flip on its head during actuation. 

**Aiming**<br>
The camera system for the robot used color recognition to detect the backboard. A raspberry Pi calculated the desired trajectory of the ball and actuated a motor that drove a turntable, rotating the entire mechanism in the yaw axis.

![PiCad](/Davinci_Portfolio/assets/BBall/piCad.png)
![turntableCad](/Davinci_Portfolio/assets/BBall/turntable.png)

**Results**<br>
The results of the competition resulted in making 7/10 baskets from the freethrow line. We won the robot comptetition against our competitors who only made 1 basket.




<!-- 
<video controls="controls" width="1920" height="1080" name="Free Throw Video">
  <source src="/Davinci_Portfolio/assets/BBall/fullview.mov">
</video> -->
## Video
<iframe width="1920" height="1080" src="/Davinci_Portfolio/assets/BBall/fullview.MOV" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


After the competition, we set up the robot at the halfcourt line for this video of a sucessful halfcourt shot.

![half_court](/Davinci_Portfolio/assets/BBall/halfcourt.gif)





<!-- * [Mastering Markdown](https://guides.github.com/features/mastering-markdown/)
* [Markdown Guide](https://www.markdownguide.org/cheat-sheet/)
* [GitHub Flavored Markdown Spec](https://github.github.com/gfm/) -->

---
<!-- 
# This is the h1 text
## This is the h2 text
### This is the h3 text
#### This is the h4 text
##### This is the h5 text
###### This is the h6 text

**Bold Text in the post will look like:**<br>
**This text is Bold**

**Italic Text in the post will look like:**<br>
*This text is Italic*

> Quotes on your post will look like this

`Codes on your post will look like this`

**Link in the post will look like:**<br>
[This is a link](#) -->



<!-- ![Team image](/Davinci_Portfolio/assets/images/Vestibular_team.jpg) -->

<!-- **Generally, there are two types of tasks that our controlling of ping-pong ball can be achieved:**

1. Follow a line trajectory drawn on a white board.
2. Follow the path solved by our maze solver algorithm, with a maze drawn on a white board. -->

<!-- ### ROS Architecture
![arch image](/Davinci_Portfolio/assets/images/bal_arch.png)

### Controls diagram
![control image](/Davinci_Portfolio/assets/images/control_diagram.png) -->


<!-- ### Position Control
<iframe src="/Davinci_Portfolio/assets/videos/pushball.gif" width="600" height="360" frameBorder="0" class="giphy-embed" allowFullScreen></iframe> -->

<!-- 
**Computer Vision:**<br>
An intel Realsense D435i camera is used detect the realtime location of the ball and the marks on the board. It does this by color thresholding the colors orange, blue, pink, and purple for the ball, waypoint 1, waypoint 2, and the maze respectivly. The vision pipeline processes and extracts the data by creating a pixel mask, calculating the contrours, and extracting the centroids of those contours. The ball coordinates are published as a Ball_Pose() msg to the ball_pose topic. The maze mask data is passed to the service callbacks relating to the maze_follow and line_follow services. It then draws all contours over image feed and displays the resulting images in realtime.

**Maze Solver Algorithm:**<br>
The Breadth First search method is used to solve the maze and generate a trajectory for the ball to follow. To do so, the algorithm computes two cost maps, one where the points farthest away from the walls of the maze are assigned the lowest value, and another cost map that assigns higher value to the points furthest away from the starting point. The algorithm adds these two maps and does gradient descent from the start point to the goal, interating through the neighboring cells and finding a path.

**Future Improvements:**<br>
When we set our start position on the corners of board, sometimes the ball is hard to be balanced initially and could cause drastic motion of robot arm. One way to solve this issue might be adding more dimensions in our control by using more joints to achieve more dynamical balance when putting the ball in any position. -->

<!-- ![arch image](/Davinci_portfolio/assets/images/bal_arch.jpg)

![control image](/Davinci_portfolio/assets/images/control_diagram.jpg) -->

<!-- ## Line Following
<iframe width="560" height="315" src="/Davinci_Portfolio/assets/videos/line_follow.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## NU Path Follow
<iframe width="560" height="315" src="/Davinci_Portfolio/assets/videos/NU_Follow.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Maze Solving
<iframe width="560" height="315" src="/Davinci_Portfolio/assets/videos/Maze_follow.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->

<!-- **YouTUbe Videos will look like:**<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/jTPXwbDtIpA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->